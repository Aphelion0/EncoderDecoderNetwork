{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INSPIRED FROM NLP FROM SCRATCH -PYTORCH OFFICIAL DOCS.\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import pickle\n",
    "import bcolz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###PHASE 1 - DATA PROCESSING (REUSABLE CODE FOR 3,4,5)######\n",
    "\n",
    "#1. Extract Glove Embedding Dictionary. Maps almost every single word in every language to vector.\n",
    "vectors = bcolz.open('6B.50.dat')[:]\n",
    "words = pickle.load(open('6B.50_words.pkl', 'rb'))\n",
    "word2idx = pickle.load(open('6B.50_idx.pkl', 'rb'))\n",
    "\n",
    "glove = {w: vectors[word2idx[w]] for w in words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#2. Initialise Language Database\n",
    "\n",
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class LanguageDatabase:\n",
    "    def __init__(self,language):\n",
    "        #At the begining only SOS and EOS characters are in vocabulary\n",
    "        self.language_name = language\n",
    "        self.num_words = 2;\n",
    "        self.word2index = {}\n",
    "        self.index2word = {0:\"SOS\",1:\"EOS\"}\n",
    "        self.word2count = {}\n",
    "    \n",
    "    def len_vocab(self):\n",
    "        return self.num_words\n",
    "    \n",
    "    def add_new(self,text):\n",
    "        for token in text.split(' '):\n",
    "            if(token not in self.word2index):\n",
    "                self.word2index[token] = self.num_words\n",
    "                self.index2word[self.num_words] = token\n",
    "                self.word2count[token] = 1\n",
    "                self.num_words+=1;\n",
    "            else:\n",
    "                self.word2count[token] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing English Text(Imperfect.. Need to be better. Know REGEX?? Pls help here)\n",
    "# Basically remove punctuations attached with text. for example 'is!' should be replaced by 'is'. 'What?' should be replaced by What.\n",
    "#Helps reduce redundancy,\n",
    "\n",
    "#Convert all chatracters to lowercase and strip trailing spaces\n",
    "def Preprocess(s):\n",
    "    s = s.lower().strip()\n",
    "    \n",
    "    #REMOVE NON LETTER CHARACTERS\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    \n",
    "    return s\n",
    "\n",
    "#BS Function -  DO SOMETHING\n",
    "def Preprocess_Hindi(s):\n",
    "    lines = re.split('\\W=',s)\n",
    "    s= \"\";\n",
    "    for l in lines:\n",
    "        if(s!=\"\"):\n",
    "            s = s + l;\n",
    "        else:\n",
    "            s = s + \" \" + l;\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#3. Read file and initialise Hindi and English Language Database.The hindi database occassionaly contains English words.\n",
    "def init_db():\n",
    "    training_en_lines = open('DataSet2/train.en',encoding='utf-8').read().strip().split('\\n')\n",
    "    training_hi_lines = open('DataSet2/train.hi',encoding='utf-8').read().strip().split('\\n')\n",
    "    validation_en_lines = open('DataSet2/dev.en',encoding='utf-8').read().strip().split('\\n')\n",
    "    validation_hi_lines = open('DataSet2/dev.hi',encoding='utf-8').read().strip().split('\\n')\n",
    "    \n",
    "    #PAIRS Structure ENGLISH -> HINDI\n",
    "    training_pairs = [[Preprocess(l1),l2] for l1,l2 in zip(training_en_lines,training_hi_lines)]\n",
    "    validation_pairs = [[Preprocess(l1),l2] for l1,l2 in zip(validation_en_lines,validation_hi_lines)]\n",
    "    \n",
    "    #ENGLISH\n",
    "    en_lang_db = LanguageDatabase('english')\n",
    "    \n",
    "    #HINDI\n",
    "    hi_lang_db = LanguageDatabase('hindi')\n",
    "    \n",
    "    print('Database Initialised. Populating....')\n",
    "    #Database must know every single word that could be present in the language in our data.\n",
    "    \n",
    "    #Training Text\n",
    "    for [en,hi] in training_pairs:\n",
    "        en_lang_db.add_new(en)\n",
    "        hi_lang_db.add_new(hi)\n",
    "        \n",
    "    #Validation Text\n",
    "    for [en,hi] in validation_pairs:\n",
    "        en_lang_db.add_new(en)\n",
    "        hi_lang_db.add_new(hi)\n",
    "        \n",
    "    print('Finished!')\n",
    "        \n",
    "    return en_lang_db,hi_lang_db,training_pairs,validation_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Initialised. Populating....\n",
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "EnglishDB,HindiDB,train_pairs,val_pairs = init_db()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Crucial Parameters - MUST BE CORRECT!\n",
    "TRAIN_VOCAB_LENGTH = EnglishDB.len_vocab()\n",
    "TRANSLATE_VOCAB_LENGTH = HindiDB.len_vocab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_Training_matrix(VOCAB_LENGTH,DB):\n",
    "    weights_matrix = np.zeros((VOCAB_LENGTH,50))\n",
    "    discovered_words = 0\n",
    "    for i in range(VOCAB_LENGTH):\n",
    "        word = DB.index2word[i]\n",
    "        try:\n",
    "            weights_matrix[i] = glove[word]\n",
    "            discovered_words+=1\n",
    "        except KeyError:\n",
    "            weights_matrix[i] = np.random.normal(scale = 0.6,size=(50,))\n",
    "    return weights_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. Extract Word Vectors for each word corresponding to indexes in database as a matrix.\n",
    "\n",
    "\n",
    "# This matrix can be multiplied with one hot representation of words to get the corresponding Glove representation\n",
    "# Initialise embedding layer weights with this matrix\n",
    "\n",
    "TRAIN_weights_matrix = torch.tensor(Get_Training_matrix(TRAIN_VOCAB_LENGTH,EnglishDB))\n",
    "#Confirmed\n",
    "TRAIN_weights_matrix[2] == torch.tensor(glove[EnglishDB.index2word[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True, True, True, True, True, True, True, True, True, True, True,\n",
       "        True, True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRANSLATION_weights_matrix = torch.tensor(Get_Training_matrix(TRANSLATE_VOCAB_LENGTH,HindiDB))\n",
    "#Confirmed\n",
    "TRANSLATION_weights_matrix[2] == torch.tensor(glove[HindiDB.index2word[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### PHASE 2 - THE MODEL ####\n",
    "#7 Embed Layer Creator with Glove Weights(Adopted from Medium Article on using Pretrained Networks)\n",
    "def init_embed_layer(weights_matrix,notrain=False):\n",
    "    num_embeddings, embeddin_dim = weights_matrix.shape\n",
    "    emb_layer = nn.Embedding(num_embeddings,embeddin_dim)\n",
    "    if notrain:\n",
    "        emb_layer.requires_grad = False\n",
    "    return emb_layer,num_embeddings,embeddin_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8. Get the pairs reading for putting in model.\n",
    "def get_tensors_from_pair(pair):\n",
    "    indexes = [EnglishDB.word2index[word] for word in pair[0].split(' ')]\n",
    "    while(len(indexes) < 100):\n",
    "        indexes.append(EOS_token)\n",
    "    input_tensor = torch.tensor(indexes, dtype=torch.long, device=device)\n",
    "    indexes = [HindiDB.word2index[word] for word in pair[1].split(' ')]\n",
    "    while(len(indexes) < 100):\n",
    "        indexes.append(EOS_token)\n",
    "    target_tensor = torch.tensor(indexes, dtype=torch.long, device=device)\n",
    "    return (input_tensor,target_tensor)\n",
    "\n",
    "training_pairs_en = [get_tensors_from_pair(p)[0] for p in train_pairs]\n",
    "training_pairs_hi = [get_tensors_from_pair(p)[1] for p in train_pairs]\n",
    "validation_pairs_en = [get_tensors_from_pair(p)[0] for p in val_pairs]\n",
    "validation_pairs_hi = [get_tensors_from_pair(p)[1] for p in val_pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TP_en = torch.stack(training_pairs_en)\n",
    "TP_hi = torch.stack(training_pairs_hi)\n",
    "VP_en = torch.stack(validation_pairs_en)\n",
    "VP_hi = torch.stack(validation_pairs_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class training_set(torch.utils.data.Dataset):\n",
    "    def __init__(self,En,Hi):\n",
    "        self.En = En                          # set data\n",
    "        self.Hi = Hi                           # set lables\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.En)                   # return length\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return [self.En[idx], self.Hi[idx]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = training_set(TP_en,TP_hi)\n",
    "validation_dataset = training_set(VP_en,VP_hi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(training_dataset, batch_size=250, shuffle=True)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_dataset, batch_size=250, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 Encoder Model using Embedding and LSTM.\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_size, embed_layer_size, hidden_layer_size,weights_matrix, n_layers=1):\n",
    "        \n",
    "        #Input size , embed_layer_size = weights_matrix.shape\n",
    "        \n",
    "        super().__init__()\n",
    "        self.hidden_layer_size = hidden_layer_size\n",
    "        self.input_size = input_size\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        #Define Embedding Layer\n",
    "        #DO NOT CHANGE THE GLOVE EMBEDDING WEIGHTS. THEY ARE PERFECTION.\n",
    "        self.embedding, num_embeddings, embeddin_dim = init_embed_layer(weights_matrix,True)\n",
    "        self.embedding.weight = nn.Parameter(weights_matrix)\n",
    "        \n",
    "        self.rnn = nn.LSTM(embed_layer_size, hidden_layer_size, n_layers)\n",
    "    \n",
    "    def forward(self, input, hidden, cell):\n",
    "        #print('INPUT SHAPE',input.shape)\n",
    "        \n",
    "        #Generate GloVe Encoding from One Hot Representation of the word\n",
    "        \n",
    "        encoding = self.embedding(input)\n",
    "        \n",
    "        #print(encoding)\n",
    "        #print(encoding.shape,hidden.shape,cell.shape)\n",
    "        #print('WORD REPRESENTATION IN ENCODER',encoding.shape)\n",
    "        outputs,(hidden,cell) = self.rnn(encoding.float(),(hidden.float(), cell.float()))\n",
    "        \n",
    "        #print('OUTPUTS SHAPE',outputs.shape,hidden.shape,cell.shape)\n",
    "        \n",
    "        #print('ENCODER DONE')\n",
    "        \n",
    "        #We only need the decoded hidden and state values for encoder.\n",
    "        return hidden,cell\n",
    "    \n",
    "    def initHidden(self,batchSize):\n",
    "        return torch.zeros(1,batchSize,self.hidden_layer_size,device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#7 Decoder Model using Embedding and LSTM.\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, embed_dim, hid_dim, weights_matrix, n_layers = 1):\n",
    "        super().__init__()\n",
    "        self.output_dim = output_dim\n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        #Define Embedding Layer\n",
    "        #DO NOT CHANGE THE GLOVE EMBEDDING WEIGHTS. THEY ARE PERFECTION.\n",
    "        self.embedding, num_embeddings, embeddin_dim = init_embed_layer(weights_matrix,True)\n",
    "        self.embedding.weight = nn.Parameter(weights_matrix)\n",
    "        \n",
    "        self.rnn = nn.LSTM(embed_dim, hid_dim, n_layers)\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "    \n",
    "    def forward(self, input, hidden, state):\n",
    "        \n",
    "        #print('INPUT SHAPE',input.shape)\n",
    "        #print('HIDDEN SHAPE',hidden.shape)\n",
    "        #print('STATE SHAPE',state.shape)\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #print('INPUT IN DECODER',input.shape)\n",
    "        #Generate GloVe Encoding from One Hot Representation of the word\n",
    "        encoding = self.embedding(input)\n",
    "        \n",
    "        #print('WORD REPRESENTATION IN DECODER',encoding.shape)\n",
    "        #print(encoding.shape,hidden.shape,state.shape)\n",
    "        outputs,(hidden,state) = self.rnn(encoding.float(),(hidden.float(), state.float()))\n",
    "        \n",
    "        #print('OUTPUTS',outputs.shape)\n",
    "        #print('HIDDEN_OUTPUTS',hidden.shape)\n",
    "        #print('HIDDEN_STATE',state.shape)\n",
    "        \n",
    "        prediction = self.fc_out(outputs.squeeze(0))\n",
    "        \n",
    "        #print(prediction.shape)\n",
    "        \n",
    "        return prediction, hidden, state\n",
    "    \n",
    "    def initHidden(self,batchSize):\n",
    "        return torch.zeros(1,batchSize,self.hid_dim,device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.device = device\n",
    "        \n",
    "    def forward(self, src, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = trg.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        h0 = self.encoder.initHidden(250)\n",
    "        cell0 = self.encoder.initHidden(250)\n",
    "        hidden, cell = self.encoder(src,h0,cell0)\n",
    "        \n",
    "        #print('HIDDEN_INPUT',hidden.shape)\n",
    "        #print('CELL_INPUT',cell.shape)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            output, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (embedding): Embedding(19279, 50)\n",
       "    (rnn): LSTM(50, 100)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (embedding): Embedding(40651, 50)\n",
       "    (rnn): LSTM(50, 100)\n",
       "    (fc_out): Linear(in_features=100, out_features=40651, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9. Initialize model params and optimizer..Potential HyperParameters.\n",
    "enc = Encoder(TRAIN_weights_matrix.shape[0], TRAIN_weights_matrix.shape[1], 100, TRAIN_weights_matrix, 1)\n",
    "dec = Decoder(TRANSLATION_weights_matrix.shape[0], TRANSLATION_weights_matrix.shape[1], 100, TRANSLATION_weights_matrix, 1)\n",
    "model = Seq2Seq(enc, dec, device).to(device)\n",
    "\n",
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        nn.init.uniform_(param.data, 1.0, 3.0)\n",
    "        \n",
    "model.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 7,223,851 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, dataloader, optimizer , clip):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    dataindex = 0\n",
    "    \n",
    "    for src,trg in dataloader:\n",
    "        \n",
    "        print('START')\n",
    "        src = src.t()\n",
    "        trg = trg.t()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        #print('SRC shape ', src.shape)\n",
    "        #print('TRG shape ', src.shape)\n",
    "        print('MODELLING')\n",
    "        output = model(src, trg)\n",
    "        print('FINISHED MODELLING')\n",
    "        #trg = [trg len, batch size]\n",
    "        #output = [trg len, batch size, output dim]\n",
    "        \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        output = output[1:].view(-1, output_dim)\n",
    "        trg = torch.flatten(trg[1:])\n",
    "        s = nn.Softmax(dim=1)\n",
    "        output = s(output)\n",
    "        #print('OK')\n",
    "        #Need to set ignore index\n",
    "        print(output)\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "        print(output<0)\n",
    "        print(trg<0)\n",
    "        loss = criterion(output, trg)\n",
    "        print(loss.item())\n",
    "        \n",
    "        #loss.backward()\n",
    "        print('OK')\n",
    "        #torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        print('STEPPED')\n",
    "        epoch_loss += loss.item()\n",
    "        dataindex+=1\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START\n",
      "MODELLING\n",
      "FINISHED MODELLING\n",
      "tensor([[2.1248e-07, 7.2887e-14, 4.1564e-09,  ..., 4.1813e-11, 2.4648e-12,\n",
      "         2.4946e-08],\n",
      "        [2.1248e-07, 7.2887e-14, 4.1564e-09,  ..., 4.1813e-11, 2.4648e-12,\n",
      "         2.4946e-08],\n",
      "        [2.1248e-07, 7.2887e-14, 4.1564e-09,  ..., 4.1813e-11, 2.4648e-12,\n",
      "         2.4946e-08],\n",
      "        ...,\n",
      "        [2.1248e-07, 7.2887e-14, 4.1564e-09,  ..., 4.1813e-11, 2.4648e-12,\n",
      "         2.4946e-08],\n",
      "        [2.1248e-07, 7.2887e-14, 4.1564e-09,  ..., 4.1813e-11, 2.4649e-12,\n",
      "         2.4944e-08],\n",
      "        [2.1248e-07, 7.2887e-14, 4.1564e-09,  ..., 4.1813e-11, 2.4649e-12,\n",
      "         2.4944e-08]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        ...,\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False],\n",
      "        [False, False, False,  ..., False, False, False]])\n",
      "tensor([False, False, False,  ..., False, False, False])\n",
      "10.61036205291748\n",
      "OK\n",
      "STEPPED\n",
      "START\n",
      "MODELLING\n"
     ]
    }
   ],
   "source": [
    "train_loss = train(model, train_loader, optimizer, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
